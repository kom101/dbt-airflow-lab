# dbt GCS Pipeline: Ingest â” Validate â” Standardize ğŸš€

Ten projekt dbt stanowi rdzeÅ„ analityczny laboratorium, realizujÄ…c proces transformacji danych w architekturze **Medallion** (Bronze â” Silver) przy uÅ¼yciu Google BigQuery.

## ğŸ› ï¸ Opis Architektury

Projekt implementuje proces "Ingest â” Validate â” Standardize" z wykorzystaniem:
- **Python Models** dla zaawansowanej walidacji danych (Dataproc Serverless).
- **SQL Models** dla transformacji i standaryzacji w BigQuery.
- **External Tables** do bezpoÅ›redniego odczytu z Google Cloud Storage.

Projekt zawiera przykÅ‚adowe dane testowe z poprawnymi i niepoprawnymi rekordami, ktÃ³re pozwalajÄ… przetestowaÄ‡ walidacjÄ™ danych na rÃ³Å¼nych poziomach.

## ğŸ“‚ Struktura Projektu i Modeli

```text
models/
â”œâ”€â”€ staging/
â”‚   â”œâ”€â”€ [schema.yml](file:///d:/projekty/dbt-airflow-lab/dbt_gcs_project/models/staging/schema.yml)          # Definicja ÅºrÃ³deÅ‚ danych i tabel zewnÄ™trznych
â”‚   â””â”€â”€ [stg_events_validated.py](file:///d:/projekty/dbt-airflow-lab/dbt_gcs_project/models/staging/stg_events_validated.py)  # Walidacja danych w Pythonie
â””â”€â”€ core/
    â”œâ”€â”€ [fct_orders.sql](file:///d:/projekty/dbt-airflow-lab/dbt_gcs_project/models/core/fct_orders.sql)      # Standaryzacja zamÃ³wieÅ„
    â””â”€â”€ [fct_order_items.sql](file:///d:/projekty/dbt-airflow-lab/dbt_gcs_project/models/core/fct_order_items.sql) # Standaryzacja pozycji zamÃ³wieÅ„
```

## ğŸ§ª Dane Testowe

Projekt zawiera plik `orders_data.csv` z przykÅ‚adowymi danymi zawierajÄ…cymi zarÃ³wno poprawne jak i niepoprawne rekordy:

- **Rekordy 1, 2, 4, 5, 6, 7, 9, 10**: Poprawne rekordy z zamÃ³wieniami.
- **Rekord 3**: Uszkodzony format JSON (`--BÅÄ„D DANYCH--`) - odrzucany przez walidacjÄ™.
- **Rekord 8**: Poprawny JSON, ale brak wymaganych pÃ³l (`order_id`, `items`) - odrzucany przez walidacjÄ™.

Model Pythonowy ([stg_events_validated.py](file:///d:/projekty/dbt-airflow-lab/dbt_gcs_project/models/staging/stg_events_validated.py)) zawiera zaawansowanÄ… walidacjÄ™:
- Sprawdza poprawnoÅ›Ä‡ skÅ‚adni JSON.
- Weryfikuje obecnoÅ›Ä‡ wymaganych pÃ³l.
- Sprawdza typ danych dla tablicy `items`.

## ğŸ”§ Konfiguracja i Uruchomienie

### **Wymagane kroki konfiguracyjne:**

1.  **Zainstaluj `gcloud` CLI** i zaloguj siÄ™: `gcloud auth login`.
2.  **Projekt GCP**: Projekt jest skonfigurowany z ID: `lrz-ecommerce-test`.
3.  **Uruchom skrypt konfiguracyjny**: `./setup_gcp.sh` lub `.\setup_gcp.ps1`. Skrypt automatycznie przeÅ›le plik `orders_data.csv` do bucketu.
4.  **Uwierzytelnienie**: `gcloud auth application-default login`.

### **Komendy dbt wewnÄ…trz kontenera:**
```bash
# Instalacja pakietÃ³w (dbt_utils, dbt_external_tables)
# UWAGA: Paczki sÄ… instalowane w /tmp/dbt_packages dla izolacji
dbt deps

# Tworzenie tabel zewnÄ™trznych
dbt run-operation stage_external_sources

# Uruchomienie potoku (target i dbt_packages sÄ… w /tmp)
dbt run

# Testowanie jakoÅ›ci danych
dbt test
```

## ğŸ—ï¸ Etapy Przetwarzania

### **Etap 1: Konfiguracja ÅºrÃ³dÅ‚a (Bronze)**
Plik [schema.yml](file:///d:/projekty/dbt-airflow-lab/dbt_gcs_project/models/staging/schema.yml) definiuje ÅºrÃ³dÅ‚o danych z Google Cloud Storage. Wykorzystujemy `dbt_external_tables` do mapowania plikÃ³w CSV na tabele BigQuery bez koniecznoÅ›ci ich fizycznego Å‚adowania.

### **Etap 2: Walidacja w Pythonie (Silver Validation)**
Model [stg_events_validated.py](file:///d:/projekty/dbt-airflow-lab/dbt_gcs_project/models/staging/stg_events_validated.py) wczytuje dane i przeprowadza walidacjÄ™ JSON-Ã³w. Wykorzystuje **Dataproc Serverless** do izolowanego przetwarzania Pythonowego, co pozwala na znacznie bardziej elastycznÄ… obsÅ‚ugÄ™ bÅ‚Ä™dÃ³w niÅ¼ czysty SQL.

### **Etap 3: Standaryzacja w SQL (Silver/Gold)**
Dwa modele SQL przeksztaÅ‚cajÄ… zwalidowane dane w relacyjnÄ… strukturÄ™:
1.  [fct_orders.sql](file:///d:/projekty/dbt-airflow-lab/dbt_gcs_project/models/core/fct_orders.sql) - ekstrahuje dane o zamÃ³wieniach.
2.  [fct_order_items.sql](file:///d:/projekty/dbt-airflow-lab/dbt_gcs_project/models/core/fct_order_items.sql) - ekstrahuje dane o pozycjach zamÃ³wieÅ„.

## ğŸ“Š Zalety tej architektury

1.  **Python dla walidacji**: Lepsza obsÅ‚uga bÅ‚Ä™dÃ³w formatowania JSON niÅ¼ w SQL.
2.  **SQL dla modelowania**: Zoptymalizowane przetwarzanie duÅ¼ych zbiorÃ³w danych w BigQuery.
3.  **Lineage**: Jasna Å›cieÅ¼ka danych: GCS â” Python Model (Clean) â” SQL Models (Standardized).
4.  **Scalability**: Wykorzystanie rozwiÄ…zaÅ„ serverless (BigQuery, Dataproc) eliminuje potrzebÄ™ zarzÄ…dzania infrastrukturÄ….

---
*Dokumentacja techniczna projektu dbt.*
